
; General purpose server parameters
[server]

; if not set, every queue section will create a queue along with
; queue class. If set, queue section is a full equivalent of qclass
no_default_queues=false

; TCP/IP port number server responds on
port=9100

; UDP port server uses for event notification
udp_port=9111

; maximum number of simultaneous connections
max_connections=100

; maximum number of processing threads
max_threads=25

; initial number of threads created for incoming requests
init_threads=10

; Server side logging
log=false

; Use name instead of IP address in job id, false by default
;use_hostname=false

; Network inactivity timeout in seconds
network_timeout=20

; When true server recreates the [bdb].path directory and reinits the
; database
reinit=false

; When true, server transforms into a daemon, detached from the 
; current program group (for UNIX only)
daemon=false

; List of network hosts allowed admin access to netschedule
;admin_host=localhost;service1

; Queues section creates static queues. It uses form
; queue_name=qclass_name
; where classes should be created by qclass_* or queue_* section
; If no_default_queues is not set and class is created by queue_*
; section, eponymous queue is created automatically and need not be
; mentioned here.
[queues]
sample=test


; BerkeleyDB related parameters
[bdb]

; directory to keep the database. It is important that this
; directory resides on local drive (not NFS)
;
; WARNING: the database directory sometimes can be recursively deleted
;          (when netscheduled started with -reinit). 
;          DO NOT keep any of your files(besides the database) in it.
path=./netschedule_data

; amount of memory allocated by BerkeleyDB for the database cache
; Berkeley DB page cache) (More is better, see private_env though)
mem_size=50M

; use private BerkeleyDB environment. If true, does not use shared memory,
; but BDB has strange memory allocation error, so do not use with mem_size
; larger than 10M
private_env=false

; maximum number of locks, lockers, and lock objects
; should be increased for bulk transactions (or large number of queues)
max_locks=125000

max_lockers=25000

max_lockobjects=25000


; when non 0 transaction LOG will be placed to memory for better performance
; as a result transactions become non-durable and there is a risk of 
; loosing the data if server fails
; (set to at least 100M if planned to have bulk transactions)
;
log_mem_size=0

; Checkpoint threshold in KB of data written
checkpoint_kb=5000

;  Checkpoint threshold in minutes since last checkpoint
checkpoint_min=5


; use syncronous or asyncronous writes (used with transactions)
sync_transactions=false

; Direct IO for database files
direct_db=false

; Direct IO for transaction logs
direct_log=true

[queue_test]

; job expiration timeout (seconds) for completed jobs 
timeout=3600

; notification timeout (seconds). 
; Worker nodes may subscribe for notification (queue events), 
; which will be sent periodically (with specified notification timeout)
notif_timeout=7

; Job execution timeout (seconds). If job is not resolved in the specified 
; amount of time (from the moment worker node receives it) 
; job will be rescheduled for another round of execution. 
; Only fixed number of retry attempts is allowed.
;
; If 0 this "timeout" is taken as a default value
run_timeout=1800

; Execution timeout precision (seconds). Server checks exipation
; every "run_timeout_precision" seconds. Lower value means job execution 
; will be controlled with geater precision, at the expense of memory
; and CPU resources on the server side
run_timeout_precision=30

; When true immediately delete successful job from the queue
delete_done=false

; Queue version control list
; ";" separated list of programs allowed to connect to the queue to submit
; and execute jobs. Versions newer than specified are allowed to connect.
; 
; Program name can contain version number like:
;    "Program 1.2.3"
;    "Program version 1.2.3"
;    "Program v. 1.2.3"
;
;program=test 2.0.0; test 1.0.0; Cgi_Tunnel2Grid 1.0.0

; List of network hosts allowed to submit jobs
;subm_host=xpubmed0; xpubmed1; xpubmed2;


; List of network hosts allowed to run worker nodes
;wnode_host=service2; service3

; Number of faiures before the job is finally marked as failed.
failed_retries=0

; How long dynamically created queue with this class will stay.
; Default is unlimited.
;empty_lifetime=172800





; Enable/Disable load balancing for this queue
lb=false

; load balancing service name
lb_service=

; load balancing collection time (seconds)
lb_collect_time=5

; For how long (seconds) job can be delayed (stalled) in the queue
; For this period load balancers seeks for a good enough worker node
; If start time for the job is delayed for more than this value
; job is scheduled to the first available node
;
; "avg_run" - current avg job run-time (for the queue) to be taken 
; as a job delay (see also lb_exec_delay_mult)
;
lb_exec_delay = 6


; lb_exec-delay multiplier for non-const(avg_run) lb_exec_delay
;
;    lb_exec_delay = lb_exec_delay_mult * avg_run_value
lb_exec_delay_mult = 1


; Policy if non-load balanced worker node comes for a job.
; Variants: "deny", "allow", "reserve"
;   deny    - alien worker node is not receving jobs, period.
;   allow   - worker node receives a job without a delay
;   reserve - worker node receives a job if the job is stalled 
;             (not picked up by any of the load balanced nodes).
;             Alien nodes play reserve computational capacity in this case.
;
lb_unknown_host=allow

; Starting point for threashold curves
;
; 
lb_curve_high = 0.8

; Load balancing threashold curves:
;
; "linear"
; "regression"
;
lb_curve_type         = linear


; Ending point for linear curve
;
lb_curve_linear_low=0.15

; Coefficient of regression
;
lb_curve_regression_a=-0.2

; Load balancing policy (how AI unit makes it's decision)
;
;  "rate" - take into account host ratings as provided by LB service
;           Tries to distribute load evenly accross the machines
;
;  "cpu_avail" - load balancing is based on CPU availability
;           If machine has an available CPU it's granted a job
;
lb_policy=rate

